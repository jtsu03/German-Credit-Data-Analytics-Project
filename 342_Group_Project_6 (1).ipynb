# Import standard data manipulation libraries
import pandas as pd
import numpy as np

# Import visualization libraries
import matplotlib.pyplot as plt
import seaborn as sns

# Import machine learning libraries from scikit-learn
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import (
    confusion_matrix,
    ConfusionMatrixDisplay,
    classification_report,
    accuracy_score,
)
from sklearn.preprocessing import StandardScaler

# Import SMOTE for handling imbalanced datasets
from imblearn.over_sampling import SMOTE

# Import warnings to manage warning messages
import warnings
from sklearn.exceptions import ConvergenceWarning

# Suppress non-critical warnings for cleaner output
warnings.filterwarnings("ignore", category=ConvergenceWarning)

# Set Seaborn style for better aesthetics
sns.set(style="whitegrid")
def load_dataset(file_path):
    """
    Load the dataset from a CSV file.

    Parameters:
    - file_path (str): Path to the CSV file.

    Returns:
    - pd.DataFrame: Loaded dataset.
    """
    try:
        data = pd.read_csv(file_path)
        print(f"Dataset '{file_path}' loaded successfully.")
        return data
    except FileNotFoundError:
        raise FileNotFoundError(f"The file '{file_path}' was not found.")

def explore_dataset(data):
    """
    Display basic information, summary statistics, and the first few rows of the dataset.

    Parameters:
    - data (pd.DataFrame): The dataset to explore.

    Returns:
    - None
    """
    print("\n--- Dataset Information ---")
    print(data.info())  # Data types and non-null counts

    print("\n--- Summary Statistics ---")
    print(data.describe())  # Summary statistics for numerical features

    print("\n--- First 5 Rows of the Dataset ---")
    print(data.head())  # Display first few rows

# Specify the file path to the dataset
file_path = 'GermanCredit.csv'

# Load the dataset
data = load_dataset(file_path)

# Explore the dataset
explore_dataset(data)
def preprocess_data(data, target_column='RESPONSE'):
    """
    Handle missing values, encode categorical variables, and separate features from target.

    Parameters:
    - data (pd.DataFrame): The raw dataset.
    - target_column (str): The name of the target variable.

    Returns:
    - X (pd.DataFrame): Feature set.
    - y (pd.Series): Target variable.
    - data_encoded (pd.DataFrame): Encoded and cleaned dataset.
    """
    # Handle missing values using forward fill
    data.ffill(inplace=True)
    print("Missing values handled using forward fill.")

    # Convert categorical variables into dummy variables
    data_encoded = pd.get_dummies(data, drop_first=True)
    print("Categorical variables encoded using one-hot encoding.")

    # Save the cleaned dataset for potential reuse
    cleaned_file = 'Cleaned_GermanCredit.csv'
    data_encoded.to_csv(cleaned_file, index=False)
    print(f"Cleaned dataset saved as '{cleaned_file}'.")

    # Verify if the target column exists
    if target_column in data_encoded.columns:
        X = data_encoded.drop(columns=[target_column])
        y = data_encoded[target_column]
        print(f"Features and target variable '{target_column}' separated.")
    else:
        raise ValueError(f"Target column '{target_column}' not found in the dataset.")

    return X, y, data_encoded

# Specify the target column
target_column = 'RESPONSE'  # Update if the target column name differs

# Preprocess the data
X, y, data_encoded = preprocess_data(data, target_column)

def plot_correlation_heatmap(data_encoded):
    """
    Visualize the correlation matrix as a heatmap.

    Parameters:
    - data_encoded (pd.DataFrame): The encoded dataset.

    Returns:
    - None
    """
    plt.figure(figsize=(12, 10))
    correlation_matrix = data_encoded.corr()

    sns.heatmap(
        correlation_matrix, 
        annot=True, 
        fmt=".2f", 
        cmap="Greens", 
        cbar=True, 
        annot_kws={"size": 6}
    )
    plt.title("Correlation Heatmap", fontsize=16)
    plt.tight_layout()
    plt.show()
    print("Correlation heatmap displayed.")

# Plot the correlation heatmap
plot_correlation_heatmap(data_encoded)

def split_and_scale(X, y, test_size=0.3, random_state=42):
    """
    Split the dataset into training and testing sets and apply standard scaling.

    Parameters:
    - X (pd.DataFrame): Feature set.
    - y (pd.Series): Target variable.
    - test_size (float): Proportion of the dataset to include in the test split.
    - random_state (int): Random seed for reproducibility.

    Returns:
    - X_train_scaled (np.ndarray): Scaled training features.
    - X_test_scaled (np.ndarray): Scaled testing features.
    - X_train (pd.DataFrame): Training features before scaling.
    - X_test (pd.DataFrame): Testing features before scaling.
    - y_train (pd.Series): Training target.
    - y_test (pd.Series): Testing target.
    - scaler (StandardScaler): Fitted scaler object.
    """
    # Split the dataset
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, 
        test_size=test_size, 
        random_state=random_state, 
        stratify=y
    )
    print(f"Data split into training and testing sets with test size = {test_size}.")

    # Initialize the scaler
    scaler = StandardScaler()

    # Fit the scaler on the training data and transform both training and testing data
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    print("Feature scaling applied using StandardScaler.")

    return X_train_scaled, X_test_scaled, X_train, X_test, y_train, y_test, scaler

# Split and scale the data
X_train_scaled, X_test_scaled, X_train, X_test, y_train, y_test, scaler = split_and_scale(X, y)

def select_top_features(data_encoded, target_column='RESPONSE', top_n=5):
    """
    Select the top N features based on their absolute correlation with the target variable.

    Parameters:
    - data_encoded (pd.DataFrame): The encoded dataset.
    - target_column (str): The name of the target variable.
    - top_n (int): Number of top features to select.

    Returns:
    - top_features (list): List of top feature names.
    """
    # Calculate absolute correlation with the target variable
    correlation_with_target = data_encoded.corr()[target_column].abs().sort_values(ascending=False)
    
    # Drop the target variable itself from the correlation calculation
    correlation_with_target = correlation_with_target.drop(labels=[target_column])
    
    # Select the top N features
    top_features = correlation_with_target.head(top_n).index.tolist()
    print(f"Top {top_n} Features by Correlation with '{target_column}': {top_features}")
    
    return top_features

# Select the top 5 features
top_features = select_top_features(data_encoded, target_column, top_n=5)

# Create datasets using only the top 5 features
X_train_top = X_train[top_features]
X_test_top = X_test[top_features]
print("Datasets with top 5 features created.")

def plot_top_features(correlation_with_target, top_n=5):
    """
    Plot a horizontal bar chart of the top N features by correlation with the target variable.

    Parameters:
    - correlation_with_target (pd.Series): Correlation values with the target.
    - top_n (int): Number of top features to plot.

    Returns:
    - None
    """
    plt.figure(figsize=(10, 6))
    sns.barplot(
        x=correlation_with_target.values[:top_n], 
        y=correlation_with_target.index[:top_n], 
        palette='viridis'
    )
    plt.xlabel('Absolute Correlation with Target Variable')
    plt.ylabel('Feature Names')
    plt.title(f'Top {top_n} Features by Correlation with Target')
    plt.tight_layout()
    plt.show()
    print(f"Bar chart for top {top_n} features displayed.")

# Calculate absolute correlation with target for plotting
correlation_with_target = data_encoded.corr()[target_column].abs().sort_values(ascending=False).drop(labels=[target_column])

# Plot the top 5 features
plot_top_features(correlation_with_target, top_n=5)

def tune_neural_network(X_train_scaled, y_train):
    """
    Perform hyperparameter tuning for a Neural Network using GridSearchCV.

    Parameters:
    - X_train_scaled (np.ndarray): Scaled training features.
    - y_train (pd.Series): Training target.

    Returns:
    - best_nn_model (MLPClassifier): Best estimator found by GridSearchCV.
    - best_params (dict): Best hyperparameters.
    """
    # Define the parameter grid for the Neural Network
    nn_param_grid = {
        'hidden_layer_sizes': [(3,), (3, 4), (3, 4, 4), (50, 50)],
        'activation': ['logistic', 'relu'],
        'solver': ['adam'],
        'max_iter': [1000, 2000],
    }

    # Initialize GridSearchCV for Neural Network
    nn_grid = GridSearchCV(
        estimator=MLPClassifier(random_state=42),
        param_grid=nn_param_grid,
        cv=3,
        scoring='accuracy',
        n_jobs=-1,
        verbose=0
    )
    print("Starting Neural Network hyperparameter tuning...")
    
    # Fit GridSearchCV
    nn_grid.fit(X_train_scaled, y_train)
    print("Neural Network hyperparameter tuning completed.")

    # Retrieve the best model and parameters
    best_nn_model = nn_grid.best_estimator_
    best_params = nn_grid.best_params_
    print(f"Best Neural Network Parameters: {best_params}")
    
    return best_nn_model, best_params

# Perform hyperparameter tuning for Neural Network using all features
best_nn_model_1a, best_params_nn_1a = tune_neural_network(X_train_scaled, y_train)

# Predict on the test set
y_pred_nn_1a = best_nn_model_1a.predict(X_test_scaled)

# Calculate and print accuracy
accuracy_nn_1a = accuracy_score(y_test, y_pred_nn_1a)
print(f"Neural Network Accuracy (All Features): {accuracy_nn_1a:.4f}")

def tune_decision_tree(X_train, y_train):
    """
    Perform hyperparameter tuning for a Decision Tree using GridSearchCV.

    Parameters:
    - X_train (pd.DataFrame): Training features before scaling.
    - y_train (pd.Series): Training target.

    Returns:
    - best_tree_model (DecisionTreeClassifier): Best estimator found by GridSearchCV.
    - best_params (dict): Best hyperparameters.
    """
    # Define the parameter grid for Decision Tree
    tree_param_grid = {
        'criterion': ['gini', 'entropy'],
        'max_depth': [3, 5, 10],
        'min_samples_split': [2, 5],
        'min_samples_leaf': [1, 2, 4],
        'max_leaf_nodes': [10, 20, 30],
    }

    # Initialize GridSearchCV for Decision Tree
    tree_grid = GridSearchCV(
        estimator=DecisionTreeClassifier(random_state=42),
        param_grid=tree_param_grid,
        cv=3,
        scoring='accuracy',
        n_jobs=-1,
        verbose=0
    )
    print("Starting Decision Tree hyperparameter tuning...")
    
    # Fit GridSearchCV
    tree_grid.fit(X_train, y_train)
    print("Decision Tree hyperparameter tuning completed.")

    # Retrieve the best model and parameters
    best_tree_model = tree_grid.best_estimator_
    best_params = tree_grid.best_params_
    print(f"Best Decision Tree Parameters: {best_params}")
    
    return best_tree_model, best_params

# Perform hyperparameter tuning for Decision Tree using all features
best_tree_model_1a, best_params_tree_1a = tune_decision_tree(X_train, y_train)

# Predict on the test set
y_pred_tree_1a = best_tree_model_1a.predict(X_test)

# Calculate and print accuracy
accuracy_tree_1a = accuracy_score(y_test, y_pred_tree_1a)
print(f"Decision Tree Accuracy (All Features): {accuracy_tree_1a:.4f}")

def plot_confusion_matrix_display(y_true, y_pred, model_name, dataset_type="Test", cmap="Greens"):
    """
    Plot the confusion matrix for the given predictions.

    Parameters:
    - y_true (pd.Series): True labels.
    - y_pred (np.array): Predicted labels.
    - model_name (str): Name of the model.
    - dataset_type (str): 'Training' or 'Test' data.
    - cmap (str): Colormap for the heatmap.

    Returns:
    - None
    """
    conf_matrix = confusion_matrix(y_true, y_pred)
    disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=np.unique(y_true))
    disp.plot(cmap=cmap)
    plt.title(f"{model_name} Confusion Matrix ({dataset_type} Data)")
    plt.show()
    print(f"Confusion matrix for {model_name} ({dataset_type} Data) displayed.")

# Plot Confusion Matrix for Neural Network (1a - All Features) on Training Data
plot_confusion_matrix_display(
    y_true=y_train, 
    y_pred=best_nn_model_1a.predict(X_train_scaled), 
    model_name="Neural Network (1a - All Features)", 
    dataset_type="Training",
    cmap="Greens"
)

# Plot Confusion Matrix for Neural Network (1a - All Features) on Test Data
plot_confusion_matrix_display(
    y_true=y_test, 
    y_pred=y_pred_nn_1a, 
    model_name="Neural Network (1a - All Features)", 
    dataset_type="Test",
    cmap="Greens"
)

# Plot Confusion Matrix for Decision Tree (1a - All Features) on Training Data
plot_confusion_matrix_display(
    y_true=y_train, 
    y_pred=best_tree_model_1a.predict(X_train), 
    model_name="Decision Tree (1a - All Features)", 
    dataset_type="Training",
    cmap="Blues"
)

# Plot Confusion Matrix for Decision Tree (1a - All Features) on Test Data
plot_confusion_matrix_display(
    y_true=y_test, 
    y_pred=y_pred_tree_1a, 
    model_name="Decision Tree (1a - All Features)", 
    dataset_type="Test",
    cmap="Blues"
)

def visualize_decision_tree(model, feature_names, class_names, title):
    """
    Visualize the structure of a Decision Tree.

    Parameters:
    - model (DecisionTreeClassifier): Trained Decision Tree model.
    - feature_names (list): List of feature names.
    - class_names (list): List of class names.
    - title (str): Title of the plot.

    Returns:
    - None
    """
    plt.figure(figsize=(20, 10))
    plot_tree(
        model,
        feature_names=feature_names,
        class_names=class_names,
        filled=True,
        rounded=True,
        fontsize=12
    )
    plt.title(title, fontsize=16)
    plt.tight_layout()
    plt.show()
    print(f"Decision Tree '{title}' visualized.")

# Define class names based on unique target labels
class_names = [str(label) for label in np.unique(y)]

# Visualize the Decision Tree trained on all features
visualize_decision_tree(
    model=best_tree_model_1a,
    feature_names=X_train.columns.tolist(),
    class_names=class_names,
    title="Decision Tree Visualization (1a - All Features)"
)
def calculate_net_profit(conf_matrix, cost_gain_matrix):
    """
    Calculate the net profit using the confusion matrix and cost/gain matrix.

    Parameters:
    - conf_matrix (np.ndarray): Confusion matrix of the model's predictions.
    - cost_gain_matrix (np.ndarray): Matrix defining the cost/gain for each outcome.

    Returns:
    - float: Net profit or loss.
    """
    net_profit = np.sum(conf_matrix * cost_gain_matrix)
    return net_profit

# Define the cost/gain matrix
# Format: [[Gain for TN, Cost for FP], [Cost for FN, Gain for TP]]
cost_gain_matrix = np.array([[50, -10], [-20, 100]])
print("Cost/Gain matrix defined.")

# Calculate net profit for Neural Network (1a - All Features)
conf_matrix_nn_1a = confusion_matrix(y_test, y_pred_nn_1a)
net_profit_nn_1a = calculate_net_profit(conf_matrix_nn_1a, cost_gain_matrix)
print(f"Neural Network (1a - All Features) Net Profit: ${net_profit_nn_1a:.2f}")

# Calculate net profit for Decision Tree (1a - All Features)
conf_matrix_tree_1a = confusion_matrix(y_test, y_pred_tree_1a)
net_profit_tree_1a = calculate_net_profit(conf_matrix_tree_1a, cost_gain_matrix)
print(f"Decision Tree (1a - All Features) Net Profit: ${net_profit_tree_1a:.2f}")

def visualize_cost_gain_matrix(conf_matrix, cost_gain_matrix, title):
    """
    Visualize the cost/gain matrix as a heatmap.

    Parameters:
    - conf_matrix (np.ndarray): Confusion matrix of the model's predictions.
    - cost_gain_matrix (np.ndarray): Matrix defining the cost/gain for each outcome.
    - title (str): Title of the heatmap.

    Returns:
    - None
    """
    # Element-wise multiplication to compute the cost/gain values
    cost_gain_values = conf_matrix * cost_gain_matrix

    # Create a DataFrame for better visualization
    matrix_df = pd.DataFrame(
        cost_gain_values, 
        columns=["Predicted Negative", "Predicted Positive"], 
        index=["Actual Negative", "Actual Positive"]
    )

    # Plot the heatmap
    plt.figure(figsize=(8, 6))
    sns.heatmap(matrix_df, annot=True, fmt=".2f", cmap="Blues", cbar=True)
    plt.title(title, fontsize=16)
    plt.xlabel("Predicted Outcomes")
    plt.ylabel("Actual Outcomes")
    plt.tight_layout()
    plt.show()
    print(f"Cost/Gain matrix visualized for {title}.")

# Visualize Cost/Gain Matrix for Neural Network (1a - All Features)
visualize_cost_gain_matrix(
    conf_matrix=conf_matrix_nn_1a, 
    cost_gain_matrix=cost_gain_matrix, 
    title="Cost/Gain Matrix (Neural Network 1a - All Features)"
)

# Visualize Cost/Gain Matrix for Decision Tree (1a - All Features)
visualize_cost_gain_matrix(
    conf_matrix=conf_matrix_tree_1a, 
    cost_gain_matrix=cost_gain_matrix, 
    title="Cost/Gain Matrix (Decision Tree 1a - All Features)"
)
def print_classification_report_custom(y_true, y_pred, model_name):
    """
    Print the classification report for the given predictions.

    Parameters:
    - y_true (pd.Series): True labels.
    - y_pred (np.ndarray): Predicted labels.
    - model_name (str): Name of the model.

    Returns:
    - None
    """
    report = classification_report(y_true, y_pred)
    print(f"\n--- Classification Report for {model_name} ---")
    print(report)

# Classification Report for Neural Network (1a - All Features)
print_classification_report_custom(
    y_true=y_test, 
    y_pred=y_pred_nn_1a, 
    model_name="Neural Network (1a - All Features)"
)

# Classification Report for Decision Tree (1a - All Features)
print_classification_report_custom(
    y_true=y_test, 
    y_pred=y_pred_tree_1a, 
    model_name="Decision Tree (1a - All Features)"
)

# Reusing the tune_decision_tree function defined earlier

# Perform hyperparameter tuning for Decision Tree using top 5 features
best_tree_model_1b, best_params_tree_1b = tune_decision_tree(X_train_top, y_train)

# Predict on the test set
y_pred_tree_1b = best_tree_model_1b.predict(X_test_top)

# Calculate and print accuracy
accuracy_tree_1b = accuracy_score(y_test, y_pred_tree_1b)
print(f"Decision Tree Accuracy (Top 5 Features): {accuracy_tree_1b:.4f}")

def tune_neural_network_top_features(X_train_top, y_train):
    """
    Perform hyperparameter tuning for a Neural Network using top features.

    Parameters:
    - X_train_top (pd.DataFrame): Training features with top selected features.
    - y_train (pd.Series): Training target.

    Returns:
    - best_nn_model (MLPClassifier): Best estimator found by GridSearchCV.
    - best_params (dict): Best hyperparameters.
    """
    # Initialize the scaler for top features
    scaler_top = StandardScaler()
    X_train_top_scaled = scaler_top.fit_transform(X_train_top)
    X_test_top_scaled = scaler_top.transform(X_test_top)

    # Define the parameter grid
    nn_param_grid = {
        'hidden_layer_sizes': [(3,), (3, 4), (3, 4, 4), (50, 50)],
        'activation': ['logistic', 'relu'],
        'solver': ['adam'],
        'max_iter': [1000, 2000],
    }

    # Initialize GridSearchCV
    nn_grid = GridSearchCV(
        estimator=MLPClassifier(random_state=42),
        param_grid=nn_param_grid,
        cv=3,
        scoring='accuracy',
        n_jobs=-1,
        verbose=0
    )
    print("Starting Neural Network hyperparameter tuning for Top 5 Features...")
    
    # Fit GridSearchCV
    nn_grid.fit(X_train_top_scaled, y_train)
    print("Neural Network hyperparameter tuning (Top 5 Features) completed.")

    # Retrieve the best model and parameters
    best_nn_model = nn_grid.best_estimator_
    best_params = nn_grid.best_params_
    print(f"Best Neural Network Parameters (Top 5 Features): {best_params}")
    
    # Predict on the test set
    y_pred_nn_1b = best_nn_model.predict(X_test_top_scaled)
    
    # Calculate accuracy
    accuracy_nn_1b = accuracy_score(y_test, y_pred_nn_1b)
    print(f"Neural Network Accuracy (Top 5 Features): {accuracy_nn_1b:.4f}")
    
    return best_nn_model, best_params, y_pred_nn_1b

# Perform hyperparameter tuning for Neural Network using top 5 features
best_nn_model_1b, best_params_nn_1b, y_pred_nn_1b = tune_neural_network_top_features(X_train_top, y_train)

def plot_confusion_matrix_display(y_true, y_pred, model_name, dataset_type="Test", cmap="Greens"):
    """
    Plot the confusion matrix for the given predictions.

    Parameters:
    - y_true (pd.Series): True labels.
    - y_pred (np.ndarray): Predicted labels.
    - model_name (str): Name of the model.
    - dataset_type (str): 'Training' or 'Test' data.
    - cmap (str): Colormap for the heatmap.

    Returns:
    - None
    """
    conf_matrix = confusion_matrix(y_true, y_pred)
    disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=np.unique(y_true))
    disp.plot(cmap=cmap)
    plt.title(f"{model_name} Confusion Matrix ({dataset_type} Data)")
    plt.show()
    print(f"Confusion matrix for {model_name} ({dataset_type} Data) displayed.")

# Step 1: Scale the top 5 training features using the same scaler used during training
# It's crucial to use the same scaler to maintain consistency
# If you saved the scaler (`scaler_top_train`) during training, load it; otherwise, fit a new scaler here

# Assuming you did NOT save the scaler, fit a new scaler on the training data
scaler_top_train = StandardScaler()
X_train_top_scaled = scaler_top_train.fit_transform(X_train_top)
print("Training data scaled using StandardScaler.")

# Step 2: Generate predictions on the training data
y_pred_nn_train_1b = best_nn_model_1b.predict(X_train_top_scaled)
print("Predictions on Training Data for Neural Network (1b - Top 5 Features) generated.")

# Plot Confusion Matrix for Decision Tree (1b - Top 5 Features) on Training Data
plot_confusion_matrix_display(
    y_true=y_train, 
    y_pred=best_tree_model_1b.predict(X_train_top), 
    model_name="Decision Tree (1b - Top 5 Features)", 
    dataset_type="Training",
    cmap="Blues"
)

# Plot Confusion Matrix for Decision Tree (1b - Top 5 Features) on Test Data
plot_confusion_matrix_display(
    y_true=y_test, 
    y_pred=y_pred_tree_1b, 
    model_name="Decision Tree (1b - Top 5 Features)", 
    dataset_type="Test",
    cmap="Blues"
)

# Plot Confusion Matrix for Neural Network (1b - Top 5 Features) on Training Data
plot_confusion_matrix_display(
    y_true=y_train, 
    y_pred=y_pred_nn_train_1b, 
    model_name="Neural Network (1b - Top 5 Features)", 
    dataset_type="Training",
    cmap="Greens"
)

# Plot Confusion Matrix for Neural Network (1b - Top 5 Features) on Test Data
plot_confusion_matrix_display(
    y_true=y_test, 
    y_pred=y_pred_nn_1b, 
    model_name="Neural Network (1b - Top 5 Features)", 
    dataset_type="Test",
    cmap="Greens"
)
# Visualize the Decision Tree trained on top 5 features
visualize_decision_tree(
    model=best_tree_model_1b,
    feature_names=top_features,
    class_names=class_names,
    title="Decision Tree Visualization (1b - Top 5 Features)"
)
# Function to calculate and print net profit
def calculate_and_print_net_profit(y_true, y_pred, model_name, cost_gain_matrix):
    """
    Calculate and print the net profit for a given model.

    Parameters:
    - y_true (pd.Series): True labels.
    - y_pred (np.ndarray): Predicted labels.
    - model_name (str): Name of the model.
    - cost_gain_matrix (np.ndarray): Cost/Gain matrix.

    Returns:
    - None
    """
    conf_matrix = confusion_matrix(y_true, y_pred)
    net_profit = calculate_net_profit(conf_matrix, cost_gain_matrix)
    print(f"{model_name} Net Profit: ${net_profit:.2f}")

# Calculate and print net profit for all models
calculate_and_print_net_profit(y_test, y_pred_nn_1a, "Neural Network (1a - All Features)", cost_gain_matrix)
calculate_and_print_net_profit(y_test, y_pred_nn_1b, "Neural Network (1b - Top 5 Features)", cost_gain_matrix)
calculate_and_print_net_profit(y_test, y_pred_tree_1a, "Decision Tree (1a - All Features)", cost_gain_matrix)
calculate_and_print_net_profit(y_test, y_pred_tree_1b, "Decision Tree (1b - Top 5 Features)", cost_gain_matrix)

# Visualize Cost/Gain Matrix for Neural Network (1a - All Features)
visualize_cost_gain_matrix(
    conf_matrix=conf_matrix_nn_1a, 
    cost_gain_matrix=cost_gain_matrix, 
    title="Cost/Gain Matrix (Neural Network 1a - All Features)"
)

# Visualize Cost/Gain Matrix for Neural Network (1b - Top 5 Features)
conf_matrix_nn_1b = confusion_matrix(y_test, y_pred_nn_1b)
visualize_cost_gain_matrix(
    conf_matrix=conf_matrix_nn_1b, 
    cost_gain_matrix=cost_gain_matrix, 
    title="Cost/Gain Matrix (Neural Network 1b - Top 5 Features)"
)

# Visualize Cost/Gain Matrix for Decision Tree (1a - All Features)
visualize_cost_gain_matrix(
    conf_matrix=conf_matrix_tree_1a, 
    cost_gain_matrix=cost_gain_matrix, 
    title="Cost/Gain Matrix (Decision Tree 1a - All Features)"
)

# Visualize Cost/Gain Matrix for Decision Tree (1b - Top 5 Features)
conf_matrix_tree_1b = confusion_matrix(y_test, y_pred_tree_1b)
visualize_cost_gain_matrix(
    conf_matrix=conf_matrix_tree_1b, 
    cost_gain_matrix=cost_gain_matrix, 
    title="Cost/Gain Matrix (Decision Tree 1b - Top 5 Features)"
)

# Print Classification Report for Neural Network (1a - All Features)
print_classification_report_custom(
    y_true=y_test, 
    y_pred=y_pred_nn_1a, 
    model_name="Neural Network (1a - All Features)"
)

# Print Classification Report for Neural Network (1b - Top 5 Features)
print_classification_report_custom(
    y_true=y_test, 
    y_pred=y_pred_nn_1b, 
    model_name="Neural Network (1b - Top 5 Features)"
)

# Print Classification Report for Decision Tree (1a - All Features)
print_classification_report_custom(
    y_true=y_test, 
    y_pred=y_pred_tree_1a, 
    model_name="Decision Tree (1a - All Features)"
)

# Print Classification Report for Decision Tree (1b - Top 5 Features)
print_classification_report_custom(
    y_true=y_test, 
    y_pred=y_pred_tree_1b, 
    model_name="Decision Tree (1b - Top 5 Features)"
)
